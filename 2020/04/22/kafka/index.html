<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>kafka | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1、kafka定义Kafka是分布式发布-订阅消息系统，它最初是由LinkedIn公司开发的，之后成为Apache项目的一部分，Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理流式数据。2、使用kafka的意义缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://yoursite.com/2020/04/22/kafka/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1、kafka定义Kafka是分布式发布-订阅消息系统，它最初是由LinkedIn公司开发的，之后成为Apache项目的一部分，Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理流式数据。2、使用kafka的意义缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2020/04/22/kafka/1.png">
<meta property="article:published_time" content="2020-04-22T11:07:42.177Z">
<meta property="article:modified_time" content="2020-05-31T12:35:35.773Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/04/22/kafka/1.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-kafka" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/22/kafka/" class="article-date">
  <time datetime="2020-04-22T11:07:42.177Z" itemprop="datePublished">2020-04-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      kafka
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1、kafka定义"><a href="#1、kafka定义" class="headerlink" title="1、kafka定义"></a>1、kafka定义</h1><pre><code>Kafka是分布式发布-订阅消息系统，它最初是由LinkedIn公司开发的，之后成为Apache项目的一部分，Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理流式数据。</code></pre><h1 id="2、使用kafka的意义"><a href="#2、使用kafka的意义" class="headerlink" title="2、使用kafka的意义"></a>2、使用kafka的意义</h1><pre><code>缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就可以按照自己的节奏进行慢慢处理。

解耦和扩展性：项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。

冗余：可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。

健壮性：消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。

异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</code></pre><h1 id="3、kafka中的ISA-AR代表什么？ISR的伸缩又指什么？"><a href="#3、kafka中的ISA-AR代表什么？ISR的伸缩又指什么？" class="headerlink" title="3、kafka中的ISA AR代表什么？ISR的伸缩又指什么？"></a>3、kafka中的ISA AR代表什么？ISR的伸缩又指什么？</h1><pre><code>ISR:In-Sync Replicas 副本同步队列
AR:Assigned Replicas 所有副本
ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</code></pre><h1 id="4、kafka中的-broker-的作用"><a href="#4、kafka中的-broker-的作用" class="headerlink" title="4、kafka中的 broker 的作用"></a>4、kafka中的 broker 的作用</h1><pre><code>broker 是消息的代理，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，然后进行业务处理，broker在中间起到一个代理保存消息的中转站。</code></pre><h1 id="5、kafka中的zookeeper起到什么作用，可以不用zookeeper吗？"><a href="#5、kafka中的zookeeper起到什么作用，可以不用zookeeper吗？" class="headerlink" title="5、kafka中的zookeeper起到什么作用，可以不用zookeeper吗？"></a>5、kafka中的zookeeper起到什么作用，可以不用zookeeper吗？</h1><pre><code>zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group的管理以及 offset的值。考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，也减少了对zookeeper的依赖，

但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举controller（从副本中选择出leader副本） 和 检测broker是否存活等等。</code></pre><h1 id="6、kafka-follower如何与leader同步数据"><a href="#6、kafka-follower如何与leader同步数据" class="headerlink" title="6、kafka follower如何与leader同步数据"></a>6、kafka follower如何与leader同步数据</h1><pre><code>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求All Alive Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用ISR的方式很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，而且Leader充分利用磁盘顺序读以及send file(zero copy)机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了Follower与Leader的消息量差。</code></pre><h1 id="7、什么情况下一个-broker-会从-isr中踢出去"><a href="#7、什么情况下一个-broker-会从-isr中踢出去" class="headerlink" title="7、什么情况下一个 broker 会从 isr中踢出去"></a>7、什么情况下一个 broker 会从 isr中踢出去</h1><pre><code>leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护 ，如果一个follower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除 。</code></pre><h1 id="8、kafka-为什么那么快"><a href="#8、kafka-为什么那么快" class="headerlink" title="8、kafka 为什么那么快"></a>8、kafka 为什么那么快</h1><pre><code>Cache Filesystem Cache PageCache缓存

顺序写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。

Zero-copy 零拷技术减少拷贝次数 
零拷贝：直接 I/O，对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，但是硬件上的数据不会拷贝一份到内核空间，而是直接拷贝至了用户空间，因此直接I/O不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。

Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。

Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。</code></pre><h1 id="9、kafka-producer如何优化打入速度"><a href="#9、kafka-producer如何优化打入速度" class="headerlink" title="9、kafka producer如何优化打入速度"></a>9、kafka producer如何优化打入速度</h1><pre><code>增加线程
提高 batch.size
增加更多 producer 实例
增加 partition 数
设置 acks=-1 时，如果延迟增大：可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；
跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</code></pre><h1 id="10、kafka-producer-打数据，ack-为-0，-1，-1-的时候代表啥，-设置-1-的时候，什么情况下，leader-会认为一条消息-commit了"><a href="#10、kafka-producer-打数据，ack-为-0，-1，-1-的时候代表啥，-设置-1-的时候，什么情况下，leader-会认为一条消息-commit了" class="headerlink" title="10、kafka producer 打数据，ack  为 0， 1， -1 的时候代表啥， 设置 -1 的时候，什么情况下，leader 会认为一条消息 commit了"></a>10、kafka producer 打数据，ack  为 0， 1， -1 的时候代表啥， 设置 -1 的时候，什么情况下，leader 会认为一条消息 commit了</h1><pre><code>1（默认）数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。
0    生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。
-1 producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit（会将确认ack的follower数据更新到Zookeeper上），这时候producer才能认为一个请求中的消息都commit了。</code></pre><h1 id="11、kafka-unclean-配置代表啥，会对-spark-streaming-消费有什么影响"><a href="#11、kafka-unclean-配置代表啥，会对-spark-streaming-消费有什么影响" class="headerlink" title="11、kafka  unclean 配置代表啥，会对 spark streaming 消费有什么影响"></a>11、kafka  unclean 配置代表啥，会对 spark streaming 消费有什么影响</h1><pre><code>unclean.leader.election.enable 为true的话，意味着非ISR集合的broker 也可以参与选举，这样有可能就会丢数据，spark streaming在消费过程中拿到的 end offset 会突然变小，导致 spark streaming job挂掉。如果unclean.leader.election.enable参数设置为true，就有可能发生数据丢失和数据不一致的情况，Kafka的可靠性就会降低；而如果unclean.leader.election.enable参数设置为false，Kafka的可用性就会降低。</code></pre><p><a href="https://blog.csdn.net/lingbo229/article/details/83751532" target="_blank" rel="noopener">详细讲解</a></p>
<h1 id="12、如果leader-crash时，ISR为空怎么办"><a href="#12、如果leader-crash时，ISR为空怎么办" class="headerlink" title="12、如果leader crash时，ISR为空怎么办"></a>12、如果leader crash时，ISR为空怎么办</h1><pre><code>kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：
true：（默认）：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。
false：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。</code></pre><h1 id="13、kafka的message格式是什么样的"><a href="#13、kafka的message格式是什么样的" class="headerlink" title="13、kafka的message格式是什么样的"></a>13、kafka的message格式是什么样的</h1><pre><code>一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成
header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成。
当magic的值为1的时候，会在magic和crc32之间多一个字节的数据：attributes(保存一些相关属性，
比如是否压缩、压缩格式等等);如果magic的值为0，那么不存在attributes属性
body是由N个字节构成的一个消息体，包含了具体的key/value消息</code></pre><h1 id="14、kafka中consumer-group-是什么概念"><a href="#14、kafka中consumer-group-是什么概念" class="headerlink" title="14、kafka中consumer group 是什么概念"></a>14、kafka中consumer group 是什么概念</h1><pre><code>同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据（组间贡献组内竞争）。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。</code></pre><h1 id="15、Kafka中的消息是否会丢失和重复消费？"><a href="#15、Kafka中的消息是否会丢失和重复消费？" class="headerlink" title="15、Kafka中的消息是否会丢失和重复消费？"></a>15、Kafka中的消息是否会丢失和重复消费？</h1><pre><code>要确定Kafka的消息是否丢失或重复，从两个方面分析入手：消息发送和消息消费。

    1、消息发送

    Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产：

    0---表示不进行消息接收是否成功的确认；
    1---表示当Leader接收成功时确认；
    -1---表示Leader和Follower都接收成功时确认；
    综上所述，有6种消息生产的情况，下面分情况来分析消息丢失的场景：

    （1）acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失；

    （2）acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，数据可能丢失；

    2、消息消费

    Kafka消息消费有两个consumer接口，Low-level API和High-level API：

    Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；

    High-level API：封装了对parition和offset的管理，使用简单；

    如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了；

    解决办法：

        针对消息丢失：同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；

        针对消息重复：将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。
        幂等性</code></pre><p><a href="https://www.javazhiyin.com/22910.html" target="_blank" rel="noopener">消息重复消费及解决参考</a></p>
<h1 id="16、为什么Kafka不支持读写分离？"><a href="#16、为什么Kafka不支持读写分离？" class="headerlink" title="16、为什么Kafka不支持读写分离？"></a>16、为什么Kafka不支持读写分离？</h1><pre><code>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。

(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历 网络→主节点内存→网络→从节点内存 这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘 这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</code></pre><h1 id="17、Kafka中是怎么体现消息顺序性的？"><a href="#17、Kafka中是怎么体现消息顺序性的？" class="headerlink" title="17、Kafka中是怎么体现消息顺序性的？"></a>17、Kafka中是怎么体现消息顺序性的？</h1><pre><code>kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.或者producer将消息发送到指定partition分区</code></pre><p><a href="https://www.cnblogs.com/imfx/p/11166869.html" target="_blank" rel="noopener">topic有序</a></p>
<h1 id="18、消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1"><a href="#18、消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1" class="headerlink" title="18、消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?"></a>18、消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</h1><pre><code>offset+1</code></pre><h1 id="19、kafka如何实现延迟队列？"><a href="#19、kafka如何实现延迟队列？" class="headerlink" title="19、kafka如何实现延迟队列？"></a>19、kafka如何实现延迟队列？</h1><pre><code>Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。

底层使用数组实现，数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask.</code></pre><p><img src="1.png" alt="时间轮"></p>
<pre><code>Kafka中到底是怎么推进时间的呢？Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的TimingWheel专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O(1)的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。</code></pre><p><a href="https://blog.csdn.net/u013256816/article/details/80697456" target="_blank" rel="noopener">参考</a></p>
<p>20.Kafka中的事务是怎么实现的？<br><a href="https://blog.csdn.net/u013256816/article/details/89135417" target="_blank" rel="noopener">参考</a></p>
<p>21.Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？<br><a href="https://blog.csdn.net/yanshu2012/article/details/54894629" target="_blank" rel="noopener">点击查看详情</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/04/22/kafka/" data-id="ckautpoj1000594rhdvoqdvjp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/04/25/WEB/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          WEB
        
      </div>
    </a>
  
  
    <a href="/2020/04/22/scala/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">scala</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/05/15/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E8%89%BA%E6%9C%AF%E6%80%BB%E7%BB%93/">并发编程艺术总结</a>
          </li>
        
          <li>
            <a href="/2020/05/14/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">git常用命令</a>
          </li>
        
          <li>
            <a href="/2020/05/09/thread/">thread</a>
          </li>
        
          <li>
            <a href="/2020/05/09/netcompile/">netcompile</a>
          </li>
        
          <li>
            <a href="/2020/05/09/API/">API</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>